HTTP/1.1 和 HTTP/2 的“队头阻塞”（Head-of-Line Blocking）问题发生在不同的层面，==这是理解它们工作原理的关键。==

### HTTP/1.1 的队头阻塞

HTTP/1.1 的队头阻塞发生在**应用层**。

想象一条单车道：HTTP/1.1 在一个 TCP 连接上，同一时间只能处理一个请求。请求和响应都必须按顺序完成。

1. **请求排队**：浏览器发出请求 A，然后请求 B、C。
    
2. **响应排队**：服务器处理请求 A，然后处理 B，最后处理 C。响应也按顺序返回。
    
3. **阻塞发生**：如果请求 A 的响应因为某种原因（比如文件太大、服务器处理时间长）被卡住了，==那么即使请求 B 和 C 已经准备好了，它们也必须**等待请求 A 的响应完成**，才能被发送。==
    

这就是 HTTP/1.1 的队头阻塞：**一个请求的阻塞会影响整个连接上所有后续的请求**。为了解决这个问题，HTTP/1.1 引入了管道化（Pipelining），但实际应用中存在很多问题，所以很少被使用。浏览器通常会通过建立多个 TCP 连接来规避这个问题，但这又会带来额外的性能开销。


### HTTP/2 的多路复用

HTTP/2 解决了 HTTP/1.1 的应用层队头阻塞问题，但它依然依赖于 TCP，因此**TCP 自身的队头阻塞仍然存在**。

HTTP/2 引入了**多路复用（Multiplexing）**的概念，其核心是**流（Stream）**和**帧（Frame）**。

1. **多条车道**：HTTP/2 在一个 TCP 连接上，将数据划分为多个独立的**流**。每个流都可以看作是一条虚拟的通道，可以同时处理多个请求和响应。
    
2. **交错传输**：每个流上的数据被分割成一个个小的、带有唯一标识符的**帧**。这些帧可以在同一个 TCP 连接上交错传输，互不影响。
    
3. **阻塞解除**：即使一个流上的数据（比如一个大文件）被阻塞了，其他流上的帧仍然可以正常传输。接收端会根据帧的标识符，将它们正确地重新组装成完整的流。
    

**所以，HTTP/2 解决了应用层面的队头阻塞**，实现了真正的并发请求和响应。

---

### 为什么说 HTTP/2 仍有队头阻塞？

HTTP/2 在应用层解决了问题，但它建立在 TCP 协议之上。TCP 本身是一个**有序的、可靠的字节流**。这意味着：

- **TCP 层的队头阻塞**：如果 TCP 字节流中的一个数据包丢失了，TCP 协议会等待该数据包重传并到达，才能将后续的数据包交给 HTTP/2 层处理。
    
- **影响所有流**：因为 TCP 不知道 HTTP/2 的流概念，所以一个 TCP 数据包的丢失会阻塞整个 TCP 连接，进而**阻塞所有 HTTP/2 流**。
    

这就像高速公路上发生了交通事故，即使你有多个车道，后面的所有车辆都会被卡住。

### 总结

- **HTTP/1.1**：**应用层**队头阻塞。在单个 TCP 连接上，请求和响应必须按顺序处理。
    
- **HTTP/2**：通过多路复用解决了**应用层**队头阻塞。但它建立在 TCP 之上，**仍受 TCP 队头阻塞的影响**。
    

为了彻底解决 TCP 的队头阻塞，新的协议**HTTP/3**应运而生。它放弃了 TCP，转而使用基于 UDP 的 **QUIC 协议**，从而在传输层就实现了多路复用，从根本上消除了队头阻塞。