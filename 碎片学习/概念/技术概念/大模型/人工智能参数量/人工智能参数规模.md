### **1. 参数规模解析**

- **B = Billion（十亿参数）**：表示模型的参数量级，直接影响计算复杂度和显存占用。

- **DeepSeek 1.5B**：15亿参数（小型模型，适合轻量级任务）
- **DeepSeek 7B**：70亿参数（主流规模，平衡性能与资源）
- **DeepSeek 70B**：700亿参数（高性能需求场景）
- **DeepSeek 671B**：6710亿参数（超大规模，对标PaLM/GPT-4）

### **2. 显存需求计算公式**

显存占用由 **参数存储 + 训练/推理额外开销** 决定：

### **（1）参数存储**

- **FP32（全精度）**：每参数4字节
- **FP16（半精度）**：每参数2字节
- **INT8量化**：每参数1字节

**计算公式**：  
`显存（GB）= 参数数量 × 每参数字节数 ÷ 1e9`

### **（2）训练阶段总显存**

需额外存储梯度、优化器状态和激活值：

- **梯度**：与参数同类型（如FP32需4字节/参数）
- **优化器状态**：Adam优化器需存储动量和方差（FP32，共8字节/参数）
- **激活值**：与批次大小、序列长度强相关（约占20%~50%总显存）

**经验公式**：  
`训练显存 ≈ 参数数量 × 20字节`  
（FP16混合精度下，优化器状态仍为FP32）

### **（3）推理阶段总显存**

仅需加载参数和少量激活值：  
`推理显存 ≈ 参数存储 × 1.2~1.5`（激活值占额外20%~50