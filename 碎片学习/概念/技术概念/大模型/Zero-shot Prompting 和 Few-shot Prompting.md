Zero-shot Prompting 和 Few-shot Prompting 都是 **“==上下文学习 (In-Context Learning)”** 的核心技术==，它们通过在**提示 (Prompt)** 中提供不同数量的例子，来引导大型语言模型 (LLM) 完成特定任务。

它们的区别非常简单：**Zero-shot 不给例子，而 Few-shot 给几个例子。**

---

### Zero-shot Prompting (零样本提示)

**Zero-shot Prompting** 是最基本的提示方法，==它不给模型任何例子，只给它一个直接的指令。模型必须完全依靠自己在预训练阶段学到的知识来理解和完成任务。==

- **工作方式：** 就像你告诉一个非常聪明的学生：“请帮我翻译这句话。”，而不需要告诉他如何翻译，因为你知道他已经掌握了翻译的能力。
    
- **优点：**
    
    - **简单高效：** 不需要准备任何例子，直接提问，非常适合简单的、常见的任务。
        
    - **用途广泛：** ==适用于模型已经掌握的通用任务==，比如总结文章、回答常识性问题、生成创意文本等。
        
- **例子：**
    
    - **指令：** “请将下面的句子翻译成英文：你好，世界。”
        
    - **模型输出：** “Hello, world.”
        

---

### Few-shot Prompting (少样本提示)

**Few-shot Prompting** ==在提示中提供 **少量（通常是 2 到 5 个）** 示例，来向模型展示你期望的输入和输出格式。==模型会通过这些例子来理解任务的模式，并根据这个模式来完成后续的任务。

- **工作方式：** 就像你给一个学生一些例题，告诉他：“你看，像这样，输入是这个，输出是那个。现在，请你按照这个模式来解决下面的问题。”
    
- **优点：**
    
    - **显著提升准确性：** ==对于特定、复杂的、或格式化的任务，提供例子可以大幅提高模型的表现，减少“幻觉”和错误。==
        
    - **引导输出格式：** 强制模型以你想要的特定格式（如 JSON、Markdown 列表等）返回结果，这对于程序化使用 LLM 非常有用