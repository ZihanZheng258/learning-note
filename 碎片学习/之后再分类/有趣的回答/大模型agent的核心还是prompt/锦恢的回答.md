最近有一个国外的朋友 Austin 给我发邮件咨询我在开发 agent 中遇到的“令人沮丧”的事情，因为他最近在开发和推广一款新的 [MCP 服务器](https://zhida.zhihu.com/search?content_id=747944371&content_type=Answer&match_order=1&q=MCP+%E6%9C%8D%E5%8A%A1%E5%99%A8&zhida_source=entity)分析器 [Shinzo](https://zhida.zhihu.com/search?content_id=747944371&content_type=Answer&match_order=1&q=Shinzo&zhida_source=entity)，想要了解一线 agent 开发的痛点和迭代系统时的兴趣点。

我想我的回信可以很好回答提问者的这个问题，所以请允许我这次换一个风格回答问题吧。

以下是我的回信内容的中文翻译：

奥斯汀，你好：

我看了你在 [https://www.youtube.com/watch?v=NHmjBIxz50w](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DNHmjBIxz50w) 发布的视频。不得不说，Shinzo 是一个非常出色的作品。如果我没理解错的话，==这个项目实现了对 MCP 服务器的调度、使用情况等进行基于可视化的分析==。

至于 [crawl4ai](https://zhida.zhihu.com/search?content_id=747944371&content_type=Answer&match_order=1&q=crawl4ai&zhida_source=entity) MCP 服务器，其实并不是我重点开发的项目。事实上，我只花了大概 5 分钟时间做它。它是作为一个辅助性的 MCP 服务器被创建出来，插在我其他的 MCP 服务器中，最终以后端智能服务的形式部署。

回到正题——在从 MCP 服务器开发到部署的工作流中，我个人认为目前最大的挑战在于工具设计、提示词迭代和[效果验证](https://zhida.zhihu.com/search?content_id=747944371&content_type=Answer&match_order=1&q=%E6%95%88%E6%9E%9C%E9%AA%8C%E8%AF%81&zhida_source=entity)这几个方面。

工具设计（Tool Design）

在功能层面，设计出符合需求的 MCP 工具（MCP Tools）理论上应该能让[大语言模型](https://zhida.zhihu.com/search?content_id=747944371&content_type=Answer&match_order=1&q=%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B&zhida_source=entity)覆盖职能工作。但它们受限于大模型自身的知识范围。

举个例子，假设你设计了一个用于查询用户数据的 MCP，但只暴露了一个单一的 SQL 查询工具。理论上，大模型只需要生成正确的 SQL 语句就能完成任务。但当你提出像“请获取最近10条用户评论”这样的请求时，结果往往并不顺畅。具体细节你可以参考我的这篇文章：

[提示词设计](https://zhida.zhihu.com/search?content_id=747944371&content_type=Answer&match_order=1&q=%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%BE%E8%AE%A1&zhida_source=entity)（Prompt Design）

这目前被广泛认为是智能体工程师最耗精力和时间的部分。==提示词既要用于引导业务逻辑，也要把先验知识通过提示词注入上下文中==。提示词的质量与系统的执行结果紧密相关，因此提示词设计是 MCP 服务器中非常关键的一环。

效果验证（Validation）

这是目前最关键也最具挑战的一环。MCP 服务器的开发并不是“今天有个好想法，写了个 MCP 服务器，然后就上线了”这么简单，而是一个持续迭代的循环。

能否迭代的关键，在于我们如何对 MCP 服务器每次结合大模型的运行进行评估和验证。简单来说，你需要对它的输出结果进行打分（0-10 分）。有了这个分数，你才能进行后续迭代甚至基模型微调。

我不确定这些讨论是否有助于厘清目前的主要挑战所在。