这话说得完全没问题，甚至在圈子里已经算是常识了。

其实现在的大模型，本质上还是数据驱动的大框架下的产物。==架构层面目前已经相当成熟和完善了，大多数我们在应用层面看到的问题，归根到底几乎都是数据上的问题。==

比如之前关于 Scaling Law 是否还继续成立，很多反对意见并不是说 Scaling Law 本身失效了，而是因为高质量的数据越来越少。模型继续扩展时，遇到的问题不是算力不够，==而是数据的瓶颈：低质数据被喂给了高质算力，自然无法继续带来符合幂律规律的提升。==

针对目前大家更关注的 Agent 泛化性不足 的现象，其实也是类似的。直观的说法是：你训练了一个 Agent，它能在美团上点外卖，==但换一个平台（比如饿了么）就完全不会了。这背后是因为大模型的训练数据主要来自互联网的大量文本，==任务更多是内容生成导向的。在具体的、非内容导向的任务执行上表现不佳也就很正常了，因为训练数据里根本没有明确告诉模型「在一个特定平台上点外卖」这种逐步操作流程。

## 数据驱动真的能够构筑任务的[格式塔](https://zhida.zhihu.com/search?content_id=745339879&content_type=Answer&match_order=1&q=%E6%A0%BC%E5%BC%8F%E5%A1%94&zhida_source=entity)吗？
做过CV工业任务的朋友应该知道，[CV模型](https://zhida.zhihu.com/search?content_id=745339879&content_type=Answer&match_order=1&q=CV%E6%A8%A1%E5%9E%8B&zhida_source=entity)最佳的性能提升方法就掺入优质图像数据，这比什么奇奇怪怪的架构有用地多。很多场景下，小几百张图片带来的性能提升就相当显著了。==AI不可能对没见过的东西做出合理的分类，这也是极其符合直觉的==。

因此，现在的一个很大的争论点和分歧点就在于：是否能让数据驱动的小怪兽通过阅读维基百科从而学会在美团app上点外卖。==你认为我们日常对于任务的「格式塔」的认知可以从单纯的文本中习得吗？==

> 格式塔（Gestalt）是一个源自德语的词语，意为“**整体**”或“**完形**”。它是一种心理学理论，强调人们倾向于将==分散的部分组织成一个有意义的整体，而不是孤立地看待各部分==。该理论的核心观点是“整体大于部分之和”，并在感知、学习、记忆和思维等领域得到广泛应用。

如果你同意这个观点，那么你就是 Agentic AI 派的人，他们认为，只需要足够精妙的算法，就能让大模型自己学会如何在美团上点外卖，而且这种能力在没有任何外部干预的情况下可以自动泛化到京东和淘宝闪购上。

你怎么看呢？==如果不选择去研究如何低成本获取 Agent 相关的数据，而是在已有的死数据里抱残守缺，反正我是不太看好==

## 说说[具身智能](https://zhida.zhihu.com/search?content_id=745339879&content_type=Answer&match_order=1&q=%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD&zhida_source=entity)中 VLA 类似的问题

更进一步说，Agent 泛化性不足不仅是当前大模型 Agent 的问题，在更广义的 具身智能 领域也是非常棘手的难题。

举个例子，现在很多场景会把一个动作序列交给 VLA（Vision-Language-Action）模型 来训练和推理。但目前很尴尬的情况是：即便是开源社区里比较好的 [VLA 模型](https://zhida.zhihu.com/search?content_id=745339879&content_type=Answer&match_order=1&q=VLA+%E6%A8%A1%E5%9E%8B&zhida_source=entity)，你让它「抓一个红色草莓放到绿色杯子里」还能做到，但如果你换成「抓一个绿色草莓放到红色杯子里」，它可能就完全失败，甚至需要换一个模型。原因就在于这些 VLA 模型的泛化性能太差了。你告诉它一些通用物体的描述和对应的抓取动作，但想让它迁移到没见过的新物体或新组合上，几乎做不到。现在很多场景下的 VLA，几乎一个任务就是一个模型，单模型很难泛化到多任务上。缺一个有空间和动作常识的上游大模型。