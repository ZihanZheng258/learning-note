**什么是共享**

下图是计算的基本结构。L1、L2、L3分别表示一级缓存、二级缓存、三级缓存，越靠近CPU的缓存，速度越快，容量也越小。所以L1缓存很小但很快，并且紧靠着在使用它的CPU内核；L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用；L3更大、更慢，并且被单个插槽上的所有CPU核共享；最后是主存，由全部插槽上的所有CPU核共享。

![[Pasted image 20250707092635.png]]

当CPU执行运算的时候，它先去L1查找所需的数据、再去L2、然后是L3，==如果最后这些缓存中都没有，所需的数据就要去主内存拿。==走得越远，运算耗费的时间就越长。所以如果你在做一些很频繁的事，你要尽量确保数据在L1缓存中。

另外，线程之间共享一份数据的时候，需要一个线程把数据写回主存，而另一个线程访问主存中相应的数据。

下面是从CPU访问不同层级数据的时间概念:

|从CPU到|大约需要的CPU周期|大约需要的时间|
|---|---|---|
|主存|-|约60-80ns|
|QPI 总线传输(between sockets, not drawn)|-|约20ns|
|L3 cache|约40-45 cycles|约15ns|
|L2 cache|约10 cycles|约3ns|
|L1 cache|约3-4 cycles|约1ns|
|寄存器|1 cycle|-|
可见CPU读取主存中的数据会比==从L1中读取慢了近2个数量级。==

**缓存行**

Cache是由很多个cache line组成的。==每个cache line通常是64字节，并且它有效地引用主内存中的一块儿地址。一个Java的long类型变量是8字节，因此在一个缓存行中可以存8个long类型的变量==。

CPU每次从主存中拉取数据时，会把相邻的数据也存入同一个cache line。

在访问一个long数组的时候，如果数组中的一个值被加载到缓存中，它会自动加载另外7个。因此你能非常快的遍历这个数组。事实上，你可以非常快速的遍历在连续内存块中分配的任意数据结构。

下面的例子是测试利用cache line的特性和不利用cache line的特性的效果对比。

在2G Hz、2核、8G内存的运行环境中测试，速度差一倍。

结果：

Loop times:30ms Loop times:65ms

**什么是伪共享**
ArrayBlockingQueue有三个成员变量： ==- takeIndex：需要被取走的元素下标 - putIndex：可被元素插入的位置的下标 - count：队列中元素的数量==

这三个变量很容易放到一个缓存行中，但是之间修改没有太多的关联。所以每次修改，都会使之前缓存的数据失效，从而不能完全达到共享的效果。

![[Pasted image 20250707095625.png]]

如上图所示，当生产者线程put一个元素到ArrayBlockingQueue时，==putIndex会修改，从而导致消费者线程的缓存中的缓存行无效，需要从主存中重新读取==。

这种无法充分使用缓存行特性的现象，称为伪共享。

对于伪共享，一般的解决方案是，增大数组元素的间隔使得由不同线程存取的元素位于不同的缓存行上，以空间换时间。

在2G Hz，2核，8G内存, jdk 1.7.0_45 的运行环境下，使用了共享机制比没有使用共享机制，速度快了4倍左右。

