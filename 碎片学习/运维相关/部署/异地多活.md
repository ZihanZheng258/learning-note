提升可用性的关键思路就是：**冗余**。

现在让我们把视角下放，把焦点放到具体的「部署细节」上来。

按照前面的分析，为了避免单点故障，应用虽然部署了多台机器，但这些机器的分布情况，我们并没有去深究。

而一个机房有很多服务器，这些服务器通常会分布在一个个「机柜」上，如果你使用的这些机器，刚好在一个机柜，还是存在风险。==如果恰好连接这个机柜的交换机 / 路由器发生故障，那么你的应用依旧有「不可用」的风险。==

部署在一个机柜有风险，那把这些机器打散，分散到不同机柜上，是不是就没问题了？

这样确实会大大降低出问题的概率。但我们依旧不能掉以轻心，因为无论怎么分散，它们总归还是在一个相同的环境下：**机房**。

看到这里你可能会想，机房出现问题的概率也太小了吧，工作了这么多年，也没让我碰上一次，有必要考虑得这么复杂吗？

但你有没有思考这样一个问题：**不同体量的系统，它们各自关注的重点是什么？**

体量很小的系统，它会重点关注「用户」规模、增长，这个阶段获取用户是一切。等用户体量上来了，这个阶段会重点关注「性能」，优化接口响应时间、页面打开速度等等，这个阶段更多是关注用户体验

等体量再大到一定规模后你会发现，「可用性」就变得尤为重要。像微信、支付宝这种全民级的应用，如果机房发生一次故障，那整个影响范围可以说是非常巨大的。

## 同城灾备

即为同城两个机房，使用热备份来同步数据，同时其中一个从库为另一个做负载均衡。

# 两地三中心

这次冗余机房，就不能部署在同一个城市了，你需要把它放到距离更远的地方，部署在「异地」。

**两地是指 2 个城市，三中心是指有 3 个机房，其中 2 个机房在同一个城市，并且同时提供服务，第 3 个机房部署在异地，只做数据灾备。**

这种架构方案，通常用在银行、金融、政企相关的项目中。它的问题还是前面所说的，启用灾备机房需要时间，而且启用后的服务，不确定能否如期工作。

想真正的抵御城市级别的故障，越来越多的互联网公司，开始实施「**异地双活**」。

## 伪异地双活

前面我们讲了同城双活，那异地双活是不是直接「照搬」同城双活的模式去部署就可以了呢？

此时两个机房都接入流量，那上海机房的请求，可能要去读写北京机房的存储，这里存在一个很大的问题：**网络延迟**。

况且，网络线路之间还会经历各种路由器、交换机等网络设备，实际延迟可能会达到 30ms ~ 100ms，如果网络发生抖动，延迟甚至会达到 1 秒

不止是延迟，远距离的网络专线质量，是远远达不到机房内网络质量的，专线网络经常会发生延迟、丢包、甚至中断的情况。总之，不能过度信任和依赖「跨城专线」。

# 真正的异地双活

既然「跨机房」调用延迟是不容忽视的因素，那我们只能尽量避免跨机房「调用」，规避这个延迟问题。

也就是说，上海机房的应用，不能再「跨机房」去读写北京机房的存储，只允许读写上海本地的存储，实现「就近访问」，这样才能避免延迟问题。

还是之前提到的问题：上海机房存储都是从库，不允许写入啊，==除非我们只允许上海机房接入「读流量」，不接收「写流量」，否则无法满足不再跨机房的要求。==

很显然，只让上海机房接收读流量的方案不现实，因为很少有项目是只有读流量，没有写流量的。所以这种方案还是不行，这怎么办？

此时，你就必须在「**存储层**」做改造了。

要想上海机房读写本机房的存储，==那上海机房的存储不能再是北京机房的从库，而是也要变为「主库」。==

你没看错，两个机房的存储必须都是「**主库**」，而且两个机房的数据还要「**互相同步**」数据，即客户端无论写哪一个机房，都能把这条数据同步到另一个机房。

==如果你对 MySQL 有所了解，MySQL 本身就提供了双主架构，它支持双向复制数据，但平时用的并不多==。而且 Redis、MongoDB 等数据库并没有提供这个功能，所以，你必须开发对应的「数据同步中间件」来实现双向同步的功能。

此外，除了数据库这种有状态的软件之外，你的项目通常还会使用到消息队列，例如 RabbitMQ、Kafka，这些也是有状态的服务，所以它们也需要开发双向同步的中间件，支持任意机房写入数据，同步至另一个机房。

看到了么，这一下子复杂度就上来了，单单针对每个数据库、队列开发同步中间件，就需要投入很大精力了。

业界也开源出了很多数据同步中间件，例如阿里的 Canal、RedisShake、MongoShake，可分别在两个机房同步 MySQL、Redis、MongoDB 数据。

很多有能力的公司，也会采用自研同步中间件的方式来做，例如饿了么、携程、美团都开发了自己的同步中间件。

但这里还会遇到一个问题，两个机房都可以写，操作的不是同一条数据那还好，如果修改的是同一条的数据，发生冲突怎么办？

- 用户短时间内发了 2 个修改请求，都是修改同一条数据
- 一个请求落在北京机房，修改 X = 1（还未同步到上海机房）
- 另一个请求落在上海机房，修改 X = 2（还未同步到北京机房）
- 两个机房以哪个为准？

也就是说，==在很短的时间内，同一个用户修改同一条数据，两个机房无法确认谁先谁后，数据发生「冲突」==。

这是一个很严重的问题，系统发生故障并不可怕，可怕的是数据发生「错误」，因为修正数据的成本太高了。我们一定要避免这种情况的发生。解决这个问题，有 2 个方案。

**第一个方案**，数据同步中间件要有自动「合并」数据、解决「冲突」的能力。

这个方案实现起来比较复杂，要想合并数据，就必须要区分出「先后」顺序。我们很容易想到的方案，就是以「时间」为标尺，以「后到达」的请求为准。

但这种方案需要两个机房的「时钟」严格保持一致才行，否则很容易出现问题。例如：

- 第 1 个请求落到北京机房，北京机房时钟是 10:01，修改 X = 1
- 第 2 个请求落到上海机房，上海机房时钟是 10:00，修改 X = 2

因为北京机房的时间「更晚」，那最终结果就会是 X = 1。但这里其实应该以第 2 个请求为准，X = 2 才对。

可见，完全「依赖」时钟的冲突解决方案，不太严谨。

所以，通常会采用第二种方案，从「源头」就避免数据冲突的发生。