所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。==何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。==

那解决办法呢?

1. `针对时间`: 我们可以采用==巧妙的算法搭配合适的数据结构==，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树；
2. `针对空间`: 无非就一个办法: ==大而化小，分而治之(hash映射)==;
3. `集群|分布式`: 通俗点来讲，单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互); 而==集群适合分布式处理，并行计算==(更多考虑节点和节点间的数据交互)