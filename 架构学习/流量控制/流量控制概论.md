任何一个系统的运算、存储、网络资源都不是无限的，==当系统资源不足以支撑外部超过预期的突发流量时，便应该要有取舍，建立面对超额流量自我保护的机制，这个机制就是微服务中常说的“限流”。==在介绍限流具体细节前，我们先一起来做一道小学三年级难度的算术四则运算场景应用题：

**场景应用题**

已知条件：

1. 系统中一个业务操作需要调用 10 个服务协作来完成
2. 该业务操作的总超时时间是 10 秒
3. 每个服务的处理时间平均是 0.5 秒
4. 集群中每个服务均部署了 20 个实例 副本

求解以下问题：

- 单个用户访问，完成一次业务操作，需要耗费系统多少处理器时间？  
    答：0.5 × 10 = 5 Sec [CPU Time](https://en.wikipedia.org/wiki/CPU_time)
- 集群中每个服务每秒最大能处理多少个请求？  
    答：(1 ÷ 0.5) × 20 = 40 [QPS](https://en.wikipedia.org/wiki/Queries_per_second)
- 假设不考虑顺序且请求分发是均衡的，在保证不超时的前提下，整个集群能持续承受最多每秒多少笔业务操作？  
    答：40 × 10 ÷ 5 = 80 [TPS](https://en.wikipedia.org/wiki/Transactions_per_second)
- 如果集群在一段时间内持续收到 100 TPS 的业务请求，会出现什么情况？  
    答：这就超纲了小学水平，得看你们家架构师的本事了。

对于最后这个问题，如果仍然按照小学生的解题思路，最大处理能力为 80 TPS 的系统遇到 100 TPS 的请求，应该能完成其中的 80 TPS，也即是只有 20 TPS 的请求失败或被拒绝才对，然而这其实是最理想的情况，也是我们追求的目标。事实上，如果不做任何处理的话，更可能出现的结果是这 100 个请求中的每一个都开始了处理，==但是大部分请求完成了其中 10 次服务调用中的 8 次或者 9 次，然后就超时没有然后了。多数服务调用都白白浪费掉，没有几个请求能够走完整笔业务操作==。譬如早期的 12306 系统就明显存在这样的问题，全国人民都上去抢票的结果是全国人民谁都买不上票。为了避免这种状况出现，一个健壮的系统需要做到恰当的流量控制，更具体地说，需要妥善解决以下三个问题：

- **依据什么限流？**：==要不要控制流量，要控制哪些流量，控制力度要有多大，==等等这些操作都没法在系统设计阶段静态地给出确定的结论，必须根据系统此前一段时间的运行状况，甚至未来一段时间的预测情况来动态决定。
- **具体如何限流？**：==解决系统具体是如何做到允许一部分请求能够通行==，而另外一部分流量实行受控制的失败降级，这必须了解掌握常用的服务限流算法和设计模式。
- **超额流量如何处理？**：超额流量可以有不同的处理策略，也==许会直接返回失败（如 429 Too Many Requests），或者被迫使它们进入降级逻辑，这种被称为否决式限流。也可能让请求排队等待，暂时阻塞一段时间后继续处理，这种被称为阻塞式限流。==