本节我们来探讨数据库是如何实现隔离性的。隔离性保证了每个事务各自读、写的数据互相独立，不会彼此影响。只从定义上就能嗅出隔离性肯定与并发密切相关，因为如果没有并发，所有事务全都是串行的，那就不需要任何隔离，或者说这样的访问具备了天然的隔离性。但现实情况不可能没有并发，要在并发下实现串行的数据访问该怎样做？几乎所有程序员都会回答：加锁同步呀！正确，现代数据库均提供了以下三种锁。

- **写锁**==（Write Lock，也叫作排他锁，eXclusive Lock，简写为 X-Lock）：如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作==，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。
    
- **读锁**（Read Lock，也叫作共享锁，Shared Lock，简写为 S-Lock）：==多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁==，所以其他事务不能对该数据进行写入，==但仍然可以读取。对于持有读锁的事务==，如果该数据只有它自己一个事务加了读锁，允许直接将其升级为写锁，然后写入数据。
    
- **范围锁**（Range Lock）：==对于某个范围直接加排他锁，在这个范围内的数据不能被写入==。如下语句是典型的加范围锁的例子：

- 请注意“范围不能被写入”与“一批数据不能被写入”的差别，即不要把范围锁理解成一组排他锁的集合。加了范围锁后，不仅无法修改该范围内已有的数据，也不能在该范围内新增或删除任何数据，后者是一组排他锁的集合无法做到的。


==串行化访问提供了强度最高的隔离性，[ANSI/ISO SQL-92](https://en.wikipedia.org/wiki/SQL-92)中定义的最高等级的隔离级别便是`可串行化`（Serializable）。==`可串行化`完全符合普通程序员对数据竞争加锁的理解，如果不考虑性能优化的话，==对事务所有读、写的数据全都加上读锁、写锁和范围锁即可做到`可串行化`==（“即可”是简化理解，实际还是很复杂的，要分成 Expanding 和 Shrinking 两阶段去处理读锁、写锁与数据间的关系，称为[Two-Phase Lock](https://en.wikipedia.org/wiki/Two-phase_locking)，2PL）。但数据库不考虑性能肯定是不行的，[并发控制理论](https://en.wikipedia.org/wiki/Concurrency_control)（Concurrency Control）==决定了隔离程度与并发能力是相互抵触的，隔离程度越高，并发访问时的吞吐量就越低==。现代数据库一定会提供除`可串行化`以外的其他隔离级别供用户使用，让用户调节隔离级别的选项，根本目的是让用户可以调节数据库的加锁方式，取得隔离性与吞吐量之间的平衡。

`可串行化`的下一个隔离级别是`可重复读`（Repeatable Read），==`可重复读`对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，但不再加范围锁==。`可重复读`比`可串行化`弱化的地方在于[幻读问题](https://en.wikipedia.org/wiki/Isolation_\(database_systems\)#Phantom_reads)（Phantom Reads），它是指在事务执行过程中，两个完全相同的范围查询得到了不同的结果集。譬如现在准备统计一下 Fenix's Bookstore 中售价小于 100 元的书有多少本，会执行以下第一条 SQL 语句：

根据前面对范围锁、读锁和写锁的定义可知，假如这条 SQL 语句在同一个事务中重复执行了两次，且这两次执行之间恰好有另外一个事务在数据库插入了一本小于 100 元的书籍，==这是会被允许的，那这两次相同的查询就会得到不一样的结果，原因是`可重复读`没有范围锁来禁止在该范围内插入新的数据==，这是一个事务受到其他事务影响，隔离性被破坏的表现。

提醒注意一点，==这里的介绍是以 ARIES 理论为讨论目标的，具体的数据库并不一定要完全遵照着理论去实现==。一个例子是 MySQL/InnoDB 的默认隔离级别为`可重复读`，但它在只读事务中可以完全避免幻读问题，譬如上面例子中事务 T1 只有查询语句，是一个只读事务，所以例子中的问题在 MySQL 中并不会出现。但在读写事务中，MySQL 仍然会出现幻读问题，==譬如例子中事务 T1 如果在其他事务插入新书后，不是重新查询一次数量，而是要将所有小于 100 元的书改名，那就依然会受到新插入书籍的影响。==

`可重复读`的下一个隔离级别是`读已提交`（Read Committed），==`读已提交`对事务涉及的数据加的写锁会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。==`读已提交`比`可重复读`弱化的地方在于[不可重复读问题](https://en.wikipedia.org/wiki/Isolation_\(database_systems\)#Non-repeatable_reads)（Non-Repeatable Reads），它是指在事务执行过程中，对同一行数据的两次查询得到了不同的结果。譬如笔者想要获取 Fenix's Bookstore 中《深入理解 Java 虚拟机》这本书的售价，同样执行了两条 SQL 语句，在此两条语句执行之间，恰好另外一个事务修改了这本书的价格，将书的价格从 90 元调整到了 110 元，如下 SQL 所示：

==如果隔离级别是`读已提交`，这两次重复执行的查询结果就会不一样，原因是`读已提交`的隔离级别缺乏贯穿整个事务周期的读锁==，无法禁止读取过的数据发生变化，此时事务 T2 中的更新语句可以马上提交成功，这也是一个事务受到其他事务影响，隔离性被破坏的表现。假如隔离级别是`可重复读`的话，==由于数据已被事务 T1 施加了读锁且读取后不会马上释放，所以事务 T2 无法获取到写锁==，更新就会被阻塞，直至事务 T1 被提交或回滚后才能提交。

`读已提交`的下一个级别是`读未提交`（Read Uncommitted），==`读未提交`对事务涉及的数据只加写锁，会一直持续到事务结束，但完全不加读锁==。`读未提交`比`读已提交`弱化的地方在于[脏读问题](https://en.wikipedia.org/wiki/Isolation_\(database_systems\)#Dirty_reads)（Dirty Reads），它是指在事务执行过程中，一个事务读取到了另一个事务未提交的数据。譬如笔者觉得《深入理解 Java 虚拟机》从 90 元涨价到 110 元是损害消费者利益的行为，又执行了一条更新语句把价格改回了 90 元，在提交事务之前，同事说这并不是随便涨价，而是印刷成本上升导致的，按 90 元卖要亏本，于是笔者随即回滚了事务，场景如下 SQL 所示：

理论上还存在更低的隔离级别，就是“完全不隔离”，即读、写锁都不加。`读未提交`会有脏读问题，但不会有脏写问题（Dirty Write），即一个事务的没提交之前的修改可以被另外一个事务的修改覆盖掉，脏写已经不单纯是隔离性上的问题了，==它将导致事务的原子性都无法实现，所以一般谈论隔离级别时不会将它纳入讨论范围内，而将`读未提交`视为是最低级的隔离级别。==